{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "48b42c70-5469-4126-bf50-480cf7c24a28",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h1>Music Genre Classification</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caee80cf-4d6c-4d59-8312-8f14f11aa2a6",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>configuration</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f6c249-a2e4-4b31-9932-c9ed768c5b77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from time import time\n",
    "import librosa\n",
    "import librosa.display\n",
    "import IPython.display as ipd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b83f037-700e-4ac8-8b4e-180bd3280029",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#CONFIG\n",
    "src_path = './music-data/audio_data' # Input audio data root directory path\n",
    "outfile_path = \"data.csv\" # Output path for extracted features\n",
    "\n",
    "NUMBER_OF_MFCC = 20 # Mel coefficients\n",
    "N_FFT = 2048  # Fourier Transform Settings\n",
    "HOP_LENGTH = 512 # Hop length on audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf40554b-83fa-4aed-bada-ed9ca2afdd35",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pop', '.DS_Store', 'metal', 'disco', 'blues', 'reggae', 'classical', 'rock', 'hiphop', 'country', 'jazz']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "genres = list(os.listdir(f'{src_path}'))\n",
    "print(genres)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09351cc7-ed50-4d41-b432-265b5240aa80",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Audio Exploration and Visualizations</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c7e701-c34f-458b-b558-e2ebc060e207",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_sig, sr_viz = librosa.load(f'{src_path}/reggae/reggae.00036.wav')\n",
    "tempo, beats = librosa.beat.beat_track(y=y_sig, sr=sr_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85534ddf-c939-4211-adea-161597c3d2eb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Load the audio file\n",
    "y_sig, sr_viz = librosa.load(f'{src_path}/reggae/reggae.00036.wav')\n",
    "\n",
    "print('y:', y_sig, '\\n')\n",
    "print('Datatype of y:', type(y_sig))\n",
    "print('Datatype of sr:', type(sr_viz), '\\n')\n",
    "print('y shape:', np.shape(y_sig), '\\n')\n",
    "print('Sampling Rate (Hz):', sr_viz, '\\n')\n",
    "\n",
    "#Verify the length of the audio\n",
    "audio_length_seconds = np.shape(y_sig)[0] / sr_viz\n",
    "print('Checking the length of the audio:', audio_length_seconds)\n",
    "ipd.Audio(f'{src_path}/reggae/reggae.00036.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d262f28e-036d-41da-8bd3-3352f7786ca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trimming any leading or trailing silences from the audio\n",
    "yt, index = librosa.effects.trim(y_sig)\n",
    "\n",
    "#Printing the durations\n",
    "print('Durations before and after trimming:\\n')\n",
    "print('Before:', librosa.get_duration(y=y_sig, sr=sr_viz), 'After:', librosa.get_duration(y=yt, sr=sr_viz), '\\n')\n",
    "\n",
    "print('Audio File:', yt, '\\n')\n",
    "print('Audio File shape:', np.shape(yt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e58645-a06d-4a5c-ac34-28c3b973a3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a figure and axes for subplots\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15, 20))\n",
    "\n",
    "#Initializing row and column indices\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "#Iterate over each genre\n",
    "for genre in genres:\n",
    "    if genre.startswith('.'): #Skip hidden files like .DS_Store\n",
    "        continue\n",
    "        \n",
    "    #Reading the first audio file\n",
    "    path = f\"{src_path}/{genre}/{genre}.00000.wav\"\n",
    "    y_sig, sampling_rate_viz = librosa.load(path)\n",
    "    \n",
    "    #Plotting the waveform\n",
    "    librosa.display.waveshow(y=y_sig, sr=sampling_rate_viz, color=\"#A300F9\", ax=axes[i][j])\n",
    "    axes[i][j].set_title(genre)\n",
    "    \n",
    "    #Updating row and column indices for the next subplot\n",
    "    if j == 1:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "\n",
    "#Adjusting layout and display the plot\n",
    "plt.suptitle(\"Waveform of Audio Files from Different Genres\\n\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3716b3ec-650f-43c9-8a6a-92b7ab170d24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Default FFT window size\n",
    "vis_n_fft = 2048\n",
    "vis_hop_length = 512\n",
    "\n",
    "#Creating a figure and axes for subplots\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15, 20))\n",
    "\n",
    "#Initializing row and column indices\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "#Iterating over each genre\n",
    "for genre in genres:\n",
    "    if genre.startswith('.'): #Skip hidden files like .DS_Store\n",
    "        continue\n",
    "        \n",
    "    #Reading the first audio file\n",
    "    file = f\"{src_path}/{genre}/{genre}.00000.wav\"\n",
    "    y_sig, sampling_rate_viz = librosa.load(file)\n",
    "    \n",
    "    #Computing the short-time Fourier transform (STFT)\n",
    "    stft_data = np.abs(librosa.stft(y=y_sig, n_fft=vis_n_fft, hop_length=vis_hop_length))\n",
    "    \n",
    "    #Convert the amplitude spectrogram to Decibels-scaled spectrogram\n",
    "    DB_viz = librosa.amplitude_to_db(stft_data, ref=np.max)\n",
    "\n",
    "    #Display the spectrogram\n",
    "    img = librosa.display.specshow(DB_viz, sr=sampling_rate_viz, hop_length=vis_hop_length, x_axis='time', y_axis='log', ax=axes[i][j])\n",
    "    fig.colorbar(img, ax=axes[i][j], format=\"%+2.0f dB\")\n",
    "\n",
    "    axes[i][j].set_title(genre)\n",
    "\n",
    "    #Update row and column indices for the next subplot\n",
    "    if j == 1:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "\n",
    "# Adjust layout and display the plot\n",
    "plt.suptitle(\"Power Spectrograms of Audio Files from Different Genres\\n\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0bb5f22-9d44-40d7-b059-8de4430709cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a figure and axes for subplots\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15, 20))\n",
    "\n",
    "#Initializing row and column indices\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "#Iterate over each genre\n",
    "for genre in genres:\n",
    "    if genre.startswith('.'): #Skip hidden files like .DS_Store\n",
    "        continue\n",
    "        \n",
    "    #Reading the first audio file\n",
    "    path = f\"{src_path}/{genre}/{genre}.00000.wav\"\n",
    "    y_sig, sampling_rate_viz = librosa.load(path)\n",
    "\n",
    "    #Calculating the spectral centroids\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=y_sig, sr=sampling_rate_viz)[0]\n",
    "    \n",
    "    # Computing the time variable for visualization\n",
    "    frames_viz = range(len(spectral_centroids))\n",
    "\n",
    "    #Converts frame counts to time (seconds)\n",
    "    ti = librosa.frames_to_time(frames_viz)\n",
    "    \n",
    "    #Plotting the waveform\n",
    "    librosa.display.waveshow(y=y_sig, sr=sampling_rate_viz, alpha=0.4, color = 'purple',ax=axes[i][j])\n",
    "    axes[i][j].plot(ti, sklearn.preprocessing.minmax_scale(spectral_centroids, axis=0), color='orange')\n",
    "    axes[i][j].set_title(genre)\n",
    "\n",
    "    # Adding x and y labels\n",
    "    axes[i][j].set_xlabel('Time (s)')\n",
    "    axes[i][j].set_ylabel('Normalized Spectral Centroids')\n",
    "    \n",
    "    #Updating row and column indices for the next subplot\n",
    "    if j == 1:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "\n",
    "#Adjusting layout and display the plot\n",
    "plt.suptitle(\"Spectral Centroid along the waveform\\n\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c9594d-2197-4e4a-a9c7-85690ee42c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a figure and axes for subplots\n",
    "fig, axes = plt.subplots(nrows=5, ncols=2, figsize=(15, 20))\n",
    "\n",
    "#Initializing row and column indices\n",
    "i = 0\n",
    "j = 0\n",
    "\n",
    "#Iterate over each genre\n",
    "for genre in genres:\n",
    "    if genre.startswith('.'): #Skip hidden files like .DS_Store\n",
    "        continue\n",
    "        \n",
    "    #Reading the first audio file\n",
    "    file = f\"{src_path}/{genre}/{genre}.00000.wav\"\n",
    "    y_sig, sampling_rate_viz = librosa.load(file)\n",
    "\n",
    "    #Calculating the spectral rolloffs\n",
    "    spectral_rolloff_viz = librosa.feature.spectral_rolloff(y=y_sig, sr=sampling_rate_viz)[0]\n",
    "    \n",
    "    # Computing the time variable for visualization\n",
    "    frames_viz = range(len(spectral_rolloff_viz))\n",
    "\n",
    "    #Converts frame counts to time (seconds)\n",
    "    ti = librosa.frames_to_time(frames_viz)\n",
    "    \n",
    "    #Plotting the waveform\n",
    "    librosa.display.waveshow(y=y_sig, sr=sampling_rate_viz, alpha=0.4, color = 'purple',ax=axes[i][j])\n",
    "    axes[i][j].plot(ti, sklearn.preprocessing.minmax_scale(spectral_rolloff_viz, axis=0), color='orange')\n",
    "    axes[i][j].set_title(genre)\n",
    "\n",
    "    # Adding x and y labels\n",
    "    axes[i][j].set_xlabel('Time (s)')\n",
    "    axes[i][j].set_ylabel('Normalized Spectral Rolloff')\n",
    "    \n",
    "    #Updating row and column indices for the next subplot\n",
    "    if j == 1:\n",
    "        i += 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j += 1\n",
    "\n",
    "#Adjusting layout and display the plot\n",
    "plt.suptitle(\"Spectral Rolloff along the waveform\\n\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434c6e7b-7428-4862-876d-789c14b457ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes= plt.subplots(nrows=5, ncols=2, figsize=(15, 20))\n",
    "i = 0\n",
    "j = 0\n",
    "for genre in genres:\n",
    "    if genre.startswith('.'): #Skip hidden files like .DS_Store\n",
    "        continue\n",
    "        \n",
    "    # Reading the first audio file\n",
    "    file = f\"{src_path}/{genre}/{genre}.00000.wav\"\n",
    "    y_sig, sampling_rate_viz = librosa.load(file)\n",
    "    \n",
    "    zero_crossing_rate_viz = librosa.feature.zero_crossing_rate(y=y_sig, hop_length = vis_hop_length)[0]\n",
    "\n",
    "    #Plot\n",
    "    axes[i][j].plot(zero_crossing_rate_viz,color = \"purple\")\n",
    "    axes[i][j].set_title(genre)\n",
    "\n",
    "    # Adding x and y labels\n",
    "    axes[i][j].set_xlabel(\"Sample Index\")\n",
    "    axes[i][j].set_ylabel(\"Amplitude\")\n",
    "\n",
    "    if(j == 1):\n",
    "        i = i + 1\n",
    "        j = 0\n",
    "    else:\n",
    "        j = j + 1\n",
    "\n",
    "plt.suptitle(\"Signal Segment with Zero-Crossings\\n\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9486121c-ed91-4486-a577-3266e7120931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the start and end points for the segment\n",
    "start_seg = 1000\n",
    "end_seg = 1200\n",
    "\n",
    "#Calculating the zero-crossing rate for reggae.00036.wav in the above defined segment\n",
    "zero_cross_rate_viz = librosa.zero_crossings(yt[start_seg:end_seg], pad=False)\n",
    "\n",
    "#Counting the number of zero crossings\n",
    "num_zero_crossings_viz = sum(zero_cross_rate_viz)\n",
    "print(\"The number of zero crossings is:\", num_zero_crossings_viz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e4f8d62-9a59-4cfd-8ee9-70c1757bdd63",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Feature Extraction from audio data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7fa2b80-479a-4227-82f3-63a2d8077d49",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
      "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
      "\n",
      "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
      "This will raise in a future version.\n",
      "\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "\n",
    "import dask\n",
    "from dask import dataframe as dd\n",
    "from dask import delayed, compute\n",
    "from dask.system import CPU_COUNT\n",
    "from dask.distributed import LocalCluster, Client  # For distributed schedulers\n",
    "from dask.diagnostics import Profiler, ResourceProfiler, CacheProfiler, visualize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0946c03",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3> Feature Extraction Pipeline </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bea7faf-0753-44e4-a73b-5515201ebe24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configuration constants\n",
    "\n",
    "path = src_path # Input audio data root directory path\n",
    "outfile_path = \"data.csv\" # Output path for extracted features\n",
    "\n",
    "NUMBER_OF_MFCC = 20\n",
    "N_FFT = 2048\n",
    "HOP_LENGTH = 512\n",
    "BLOCK_LENGTH = 11\n",
    "FRAME_LENGTH = 6616\n",
    "HOP_LENGTH_STREAM = 6615\n",
    "\n",
    "def extract_features(trial_audio_file_path: str) -> pd.DataFrame:\n",
    "    #Extracting features for each chunk of the audio file\n",
    "    # print(\"Started processing file\")\n",
    "    df0 = extract_features_per_chunk(trial_audio_file_path)\n",
    "    # print(\"Ended processing file\")\n",
    "    #Concatenate dataframes\n",
    "    df0 = pd.concat(df0)\n",
    "    return df0\n",
    "\n",
    "def extract_features_per_chunk(audio_file_path):\n",
    "    # print(\"Started features per chunk\")\n",
    "    stream = librosa.stream(audio_file_path, block_length=BLOCK_LENGTH, frame_length=FRAME_LENGTH, hop_length=HOP_LENGTH_STREAM)\n",
    "    processed_chunks = []\n",
    "    for i, y_block in enumerate(stream):\n",
    "        #Trimming starting and trailing silences\n",
    "        y_trimmed, _ = librosa.effects.trim(y_block)\n",
    "        #Extracting features from trimmed audio\n",
    "        df = extract_feature_means(y_block, f'{audio_file_path}', 22050)\n",
    "        df['label'] = audio_file_path.split(\"/\")[-2]\n",
    "        processed_chunks.append(df)\n",
    "    # print(\"Ended features per chunk\")\n",
    "    return processed_chunks\n",
    "\n",
    "def extract_feature_means(signal, audio_file_path, sr) -> pd.DataFrame:\n",
    "    # print(\"Started feature means\")\n",
    "    # print(f\"{audio_file_path}\")\n",
    "    n_fft = N_FFT\n",
    "    hop_length = HOP_LENGTH\n",
    "    # print(\"1\")\n",
    "    #Computing Short-time Fourier Transform (STFT) and spectrograms\n",
    "    d_audio = np.abs(librosa.stft(signal, n_fft=n_fft, hop_length=hop_length))\n",
    "    # print(\"2\")\n",
    "    db_audio = librosa.amplitude_to_db(d_audio, ref = np.max)\n",
    "    # print(\"3\")\n",
    "    #Extracting harmonic and percussive components\n",
    "    y_harm, y_perc = librosa.effects.hpss(signal)\n",
    "    # print(\"4\")\n",
    "    #Computing spectral centroids\n",
    "    spectral_centroids = librosa.feature.spectral_centroid(y=signal, sr=sr)[0]\n",
    "    # print(\"5\")\n",
    "    spectral_centroids_delta = librosa.feature.delta(spectral_centroids)\n",
    "    # print(\"6\")\n",
    "    spectral_centroids_accelerate = librosa.feature.delta(spectral_centroids, order=2)\n",
    "    # print(\"7\")\n",
    "    #Computing chroma features\n",
    "    chromagram = librosa.feature.chroma_stft(y=signal, sr=sr, hop_length=hop_length)\n",
    "    # print(\"8\")\n",
    "    #Computing tempo (beats per minute) and spectral rolloff\n",
    "    # tempo_y, _ = librosa.beat.beat_track(y=signal, sr=sr)\n",
    "    # print(\"9\")\n",
    "    spectral_rolloff = librosa.feature.spectral_rolloff(y=signal, sr=sr)[0]\n",
    "    # print(\"10\")\n",
    "    #Computing spectral flux and spectral bandwidth\n",
    "    onset_env = librosa.onset.onset_strength(y=signal, sr=sr)\n",
    "    # print(\"11\")\n",
    "    spectral_bandwidth_2 = librosa.feature.spectral_bandwidth(y=signal, sr=sr)[0]\n",
    "    # print(\"12\")\n",
    "    spectral_bandwidth_3 = librosa.feature.spectral_bandwidth(y=signal, sr=sr, p=3)[0]\n",
    "    # print(\"13\")\n",
    "    spectral_bandwidth_4 = librosa.feature.spectral_bandwidth(y=signal, sr=sr, p=4)[0]\n",
    "    # print(\"14\")\n",
    "    #Computing the Mel Spectrograms\n",
    "    s_audio = librosa.feature.melspectrogram(y=signal, sr=sr)\n",
    "    # print(\"15\")\n",
    "    s_db_audio = librosa.amplitude_to_db(s_audio, ref=np.max)\n",
    "    # print(\"16\")\n",
    "    #Creating a dictionary to store audio features\n",
    "    audio_features = {\n",
    "        \"file_name\": audio_file_path,\n",
    "        \"zero_crossing_rate_mean\": np.mean(librosa.feature.zero_crossing_rate(y=signal)[0]),\n",
    "        \"zero_crossings_mean\": np.sum(librosa.zero_crossings(y=signal, pad=False)),\n",
    "        \"spectrogram_mean\": np.mean(db_audio[0]),\n",
    "        \"mel_spectrogram_mean\": np.mean(s_db_audio[0]),\n",
    "        \"harmonics_mean\": np.mean(y_harm),\n",
    "        \"perceptual_shock_wave_mean\": np.mean(y_perc),\n",
    "        \"spectral_centroids_mean\": np.mean(spectral_centroids),\n",
    "        \"spectral_centroids_delta_mean\": np.mean(spectral_centroids_delta),\n",
    "        \"spectral_centroids_accelerate_mean\": np.mean(spectral_centroids_accelerate),\n",
    "        \"chroma1_mean\": np.mean(chromagram[0]),\n",
    "        \"chroma2_mean\": np.mean(chromagram[1]),\n",
    "        \"chroma3_mean\": np.mean(chromagram[2]),\n",
    "        \"chroma4_mean\": np.mean(chromagram[3]),\n",
    "        \"chroma5_mean\": np.mean(chromagram[4]),\n",
    "        \"chroma6_mean\": np.mean(chromagram[5]),\n",
    "        \"chroma7_mean\": np.mean(chromagram[6]),\n",
    "        \"chroma8_mean\": np.mean(chromagram[7]),\n",
    "        \"chroma9_mean\": np.mean(chromagram[8]),\n",
    "        \"chroma10_mean\": np.mean(chromagram[9]),\n",
    "        \"chroma11_mean\": np.mean(chromagram[10]),\n",
    "        \"chroma12_mean\": np.mean(chromagram[11]),\n",
    "        # \"tempo_bpm\": tempo_y,\n",
    "        \"spectral_rolloff_var\": np.var(spectral_rolloff),\n",
    "        \"spectral_flux_var\": np.var(onset_env),\n",
    "        \"spectral_bandwidth_2_var\": np.var(spectral_bandwidth_2),\n",
    "        \"spectral_bandwidth_3_var\": np.var(spectral_bandwidth_3),\n",
    "        \"spectral_bandwidth_4_var\": np.var(spectral_bandwidth_4),\n",
    "        \"zero_crossing_rate_var\": np.var(librosa.feature.zero_crossing_rate(y=signal)[0]),\n",
    "        \"zero_crossings_var\": np.var(librosa.zero_crossings(y=signal, pad=False)),\n",
    "        \"spectrogram_var\": np.var(db_audio[0]),\n",
    "        \"mel_spectrogram_var\": np.var(s_db_audio[0]),\n",
    "        \"harmonics_var\": np.var(y_harm),\n",
    "        \"perceptual_shock_wave_var\": np.var(y_perc),\n",
    "        \"spectral_centroids_var\": np.var(spectral_centroids),\n",
    "        \"spectral_centroids_delta_var\": np.var(spectral_centroids_delta),\n",
    "        \"spectral_centroids_accelerate_var\": np.var(spectral_centroids_accelerate),\n",
    "        \"chroma1_var\": np.var(chromagram[0]),\n",
    "        \"chroma2_var\": np.var(chromagram[1]),\n",
    "        \"chroma3_var\": np.var(chromagram[2]),\n",
    "        \"chroma4_var\": np.var(chromagram[3]),\n",
    "        \"chroma5_var\": np.var(chromagram[4]),\n",
    "        \"chroma6_var\": np.var(chromagram[5]),\n",
    "        \"chroma7_var\": np.var(chromagram[6]),\n",
    "        \"chroma8_var\": np.var(chromagram[7]),\n",
    "        \"chroma9_var\": np.var(chromagram[8]),\n",
    "        \"chroma10_var\": np.var(chromagram[9]),\n",
    "        \"chroma11_var\": np.var(chromagram[10]),\n",
    "        \"chroma12_var\": np.var(chromagram[11]),\n",
    "        \"spectral_rolloff_var\": np.var(spectral_rolloff),\n",
    "        \"spectral_flux_var\": np.var(onset_env),\n",
    "        \"spectral_bandwidth_2_var\": np.var(spectral_bandwidth_2),\n",
    "        \"spectral_bandwidth_3_var\": np.var(spectral_bandwidth_3),\n",
    "        \"spectral_bandwidth_4_var\": np.var(spectral_bandwidth_4),\n",
    "    }\n",
    "    #Extracting MFCC features\n",
    "    mfcc_df = extract_mfcc_feature_means(audio_file_path, signal, sample_rate=sr, number_of_mfcc=NUMBER_OF_MFCC)\n",
    "\n",
    "    #Combining audio features and MFCC features into a single dataframe\n",
    "    df = pd.DataFrame.from_records(data=[audio_features])\n",
    "    df = pd.merge(df, mfcc_df, on='file_name')\n",
    "    # print(\"Ended feature means\")\n",
    "    return df\n",
    "\n",
    "def extract_mfcc_feature_means(audio_file_name: str, signal: np.ndarray, sample_rate: int, number_of_mfcc: int) -> pd.DataFrame:\n",
    "    # print(\"Started mfcc feature means\")\n",
    "    #Computing MFCC features\n",
    "    mfcc_alt = librosa.feature.mfcc(y=signal, sr=sample_rate, n_mfcc=number_of_mfcc)\n",
    "    delta = librosa.feature.delta(mfcc_alt)\n",
    "    accelerate = librosa.feature.delta(mfcc_alt, order=2)\n",
    "\n",
    "    #Creating a dictionary to store MFCC features\n",
    "    mfcc_features = {\"file_name\": audio_file_name}\n",
    "    for i in range(0, number_of_mfcc):\n",
    "        mfcc_features[f'mfcc{i}_mean'] = np.mean(mfcc_alt[i])\n",
    "        mfcc_features[f'mfcc_delta_{i}_mean'] = np.mean(delta[i])\n",
    "        mfcc_features[f'mfcc_accelerate_{i}_mean'] = np.mean(accelerate[i])\n",
    "    # print(\"Ended mfcc feature means\")\n",
    "    return pd.DataFrame.from_records(data=[mfcc_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe0c1fdc-d51b-4b91-af3e-2d9cb2552096",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def list_files_recursively(directory):\n",
    "    file_paths = []\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            if filename.startswith('.'): #Skip hidden files like .DS_Store\n",
    "                continue\n",
    "            file_path = os.path.join(root, filename)\n",
    "            file_paths.append(file_path)\n",
    "    return file_paths\n",
    "\n",
    "files = list_files_recursively(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97df8639",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3> Estimating Feature Extraction Times </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "02189510",
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBSET_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158fbf59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Serial code\n",
    "start = time()\n",
    "with mp.Pool(1) as p:\n",
    "    for i in files[:SUBSET_SIZE]:\n",
    "        p.apply(extract_features, (i,))\n",
    "serial_extraction_time = time()-start\n",
    "print(f'took {time()-start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cff6c7c-ba7c-46c8-b6fd-2f85ead28d16",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Mutiprocessing module</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df72b459-da3d-418b-9c80-9b77be2c8943",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with mp.Pool(2) as p:\n",
    "    for i in files[:SUBSET_SIZE]:\n",
    "        p.apply(extract_features, (i,))\n",
    "print(f'took {time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbaf4565-5156-4f02-8679-c743a12623d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with mp.Pool(2) as p:\n",
    "    for i in files[:SUBSET_SIZE]:\n",
    "        res = p.apply_async(extract_features, (i,))\n",
    "        res.get()\n",
    "print(f'took {time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21264e58-3d32-494b-ae2d-8dd3f664b02c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with mp.Pool(2) as p:\n",
    "    res = p.map(extract_features, files[:SUBSET_SIZE])\n",
    "print(f'took {time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c8fbfd-9ce2-4699-b753-41c00e5228ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with mp.Pool(2) as p:\n",
    "    res = p.map_async(extract_features, files[:SUBSET_SIZE])\n",
    "    res.get()\n",
    "print(f'took {time()-start} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9e41bf-6f5f-4e21-a605-816819f8699b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "jobs = []\n",
    "for i in files[:SUBSET_SIZE]:\n",
    "    p1 = mp.Process(target=extract_features, args=(i,))\n",
    "    p1.start()\n",
    "    jobs.append(p1)\n",
    "for job in jobs:\n",
    "    job.join()\n",
    "p1.close()\n",
    "print(f'took {time()-start} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "540145ce-8969-44b4-80a8-b9f911e1e916",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h4>Parallel with Dask</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "92f59975-b2f9-4d44-be0e-0c6a86b0dfe3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Setting the number of workers\n",
    "n_workers = min(4, CPU_COUNT)\n",
    "\n",
    "def try_scheduler(scheduler_name, files):\n",
    "    print(f\"Scheduler: {scheduler_name}\")\n",
    "    start = time()\n",
    "\n",
    "    if scheduler_name == \"distributed\":\n",
    "        #Using Local Cluster for distributed scheduler\n",
    "        # cluster = LocalCluster(n_workers=n_workers)  \n",
    "        client = Client(n_workers=5, threads_per_worker=2)\n",
    "    else:\n",
    "        dask.config.set(scheduler=scheduler_name, num_workers=n_workers)  # Set the scheduler for threads or processes or synchronous\n",
    "    \n",
    "    res = []\n",
    "    for file_path in files:\n",
    "        f = delayed(extract_features)(file_path)\n",
    "        res.append(f)\n",
    "        \n",
    "    extracted_features = delayed(pd.concat)(res)\n",
    "    df = compute(extracted_features)\n",
    "\n",
    "    if scheduler_name == \"distributed\":\n",
    "        cluster.close()  # Close the local cluster\n",
    "\n",
    "    duration = time() - start\n",
    "    print(f\"Extracted features in {duration} seconds\\n\")\n",
    "    return duration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fe345a-8a0c-43e7-8d4c-cad4c2ac1a92",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler: synchronous\n"
     ]
    }
   ],
   "source": [
    "#Comparison between different dask schedulers to see which is best with available Dask schedulers\n",
    "schedulers = [\"synchronous\", \"threads\", \"processes\", \"distributed\"]\n",
    "execution_times = []\n",
    "for scheduler in schedulers:\n",
    "    execution_time = try_scheduler(scheduler, files[:SUBSET_SIZE])\n",
    "    execution_times.append(execution_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bc6864-cac1-45fa-bb58-cff636d3b5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the speedup achieved by using parallel on feature extraction\n",
    "parallel_extraction_time = min(execution_times)\n",
    "speedup_feature_extraction = serial_extraction_time / parallel_extraction_time\n",
    "\n",
    "print(\"Speedup achieved for feature extraction: \", round(speedup_feature_extraction))\n",
    "\n",
    "#Calculating the efficiency achieved by using parallel on feature extraction\n",
    "efficiency_feature_extraction = speedup_feature_extraction / n_workers\n",
    "\n",
    "print(\"Efficiency achieved for feature extraction: \", round(efficiency_feature_extraction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352b218e-a255-4b7c-baad-bc7281f81776",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting the execution time comparison for each scheduler\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "bars = plt.bar(schedulers, execution_times, color='skyblue')\n",
    "plt.xlabel('Schedulers')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.title('Extraction Time comparison of Dask Schedulers for 50 audio files')\n",
    "\n",
    "#Displaying time on top of each bar\n",
    "for bar, time_value in zip(bars, execution_times):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{time_value:.2f}', \n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9b473e04-0939-4f8d-bc2b-3f409d4e6a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel feature extraction using the Dask Distributed Scheduler\n",
    "def extract_features_distributed(files, n_workers):\n",
    "    # cluster = LocalCluster()\n",
    "    client = Client(n_workers=5, threads_per_worker=2)\n",
    "    \n",
    "    res = []\n",
    "    for file_path in files:\n",
    "        f = delayed(extract_features)(file_path)\n",
    "        res.append(f)\n",
    "\n",
    "    extracted_features = delayed(pd.concat)(res)\n",
    "    with Profiler() as prof, ResourceProfiler() as rprof, CacheProfiler() as cprof:\n",
    "        df = compute(extracted_features)\n",
    "    visualize([prof, rprof, cprof])\n",
    "    \n",
    "    client.close()\n",
    "    # cluster.close()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7e4365-f740-43f4-a5fb-7a2df27a087a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Range of CPUs to test\n",
    "num_workers = [7, 10, 14, 20, 28]\n",
    "\n",
    "#List to store execution times\n",
    "execution_times = []\n",
    "\n",
    "#Extracting features for each configuration and recording execution time\n",
    "for n_workers in num_workers:\n",
    "    start = time()\n",
    "    df = extract_features_distributed(files, n_workers)\n",
    "    duration = time() - start\n",
    "    execution_times.append(duration)\n",
    "    print(f\"FEATURE EXTRACTION: Number of CPUs: {n_workers}\\tTime taken: {duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "77297194-7743-4336-b48c-29ce7a3672ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logs for tcp://127.0.0.1:50052:\n",
      "\n",
      "(('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO - Starting Worker plugin shuffle'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Local Directory: /var/folders/s0/my61_z_12tn1l1j8crj94kmw0000gn/T/dask-scratch-space/worker-0daxmw8m'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -                Memory:                   3.20 GiB'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          dashboard at:            127.0.0.1:50061'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -           Worker name:                          4'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:50052'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:50052'))\n",
      "Logs for tcp://127.0.0.1:50053:\n",
      "\n",
      "(('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO - Starting Worker plugin shuffle'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Local Directory: /var/folders/s0/my61_z_12tn1l1j8crj94kmw0000gn/T/dask-scratch-space/worker-q0kww953'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -                Memory:                   3.20 GiB'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          dashboard at:            127.0.0.1:50060'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -           Worker name:                          2'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:50053'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:50053'))\n",
      "Logs for tcp://127.0.0.1:50054:\n",
      "\n",
      "(('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,829 - distributed.worker - INFO - Starting Worker plugin shuffle'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Local Directory: /var/folders/s0/my61_z_12tn1l1j8crj94kmw0000gn/T/dask-scratch-space/worker-vhasqeee'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -                Memory:                   3.20 GiB'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          dashboard at:            127.0.0.1:50058'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -           Worker name:                          1'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:50054'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:50054'))\n",
      "Logs for tcp://127.0.0.1:50055:\n",
      "\n",
      "(('INFO', '2024-10-24 16:40:41,831 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,831 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO - Starting Worker plugin shuffle'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Local Directory: /var/folders/s0/my61_z_12tn1l1j8crj94kmw0000gn/T/dask-scratch-space/worker-46nh4vy4'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -                Memory:                   3.20 GiB'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          dashboard at:            127.0.0.1:50059'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -           Worker name:                          0'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:50055'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:50055'))\n",
      "Logs for tcp://127.0.0.1:50056:\n",
      "\n",
      "(('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO -         Registered to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,830 - distributed.worker - INFO - Starting Worker plugin shuffle'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Local Directory: /var/folders/s0/my61_z_12tn1l1j8crj94kmw0000gn/T/dask-scratch-space/worker-nlnlga0_'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -                Memory:                   3.20 GiB'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -               Threads:                          2'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - -------------------------------------------------'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO - Waiting to connect to:      tcp://127.0.0.1:50039'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          dashboard at:            127.0.0.1:50057'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -           Worker name:                          3'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -          Listening to:      tcp://127.0.0.1:50056'), ('INFO', '2024-10-24 16:40:41,647 - distributed.worker - INFO -       Start worker at:      tcp://127.0.0.1:50056'))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n",
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/librosa/core/pitch.py:101: UserWarning: Trying to estimate tuning from empty frequency set.\n",
      "  return pitch_tuning(\n"
     ]
    }
   ],
   "source": [
    "#FINAL\n",
    "# try_scheduler(\"distributed\", files[:SUBSET_SIZE])\n",
    "# for file_path in files:\n",
    "#     f = extract_features(file_path)\n",
    "#     res.append(f)\n",
    "#     break\n",
    "df = extract_features_distributed(files, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d92620-72d9-427b-9b0d-7faced59a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting execution times as a bar chart with equal spacing\n",
    "plt.figure(figsize=(10, 6))\n",
    "bar_width = 0.5  # Adjust the width of the bars as needed\n",
    "x_ticks = np.arange(len(num_workers))  # Position of the ticks\n",
    "\n",
    "bars = plt.bar(x_ticks, execution_times, color='skyblue', width=bar_width)\n",
    "plt.xlabel('Number of CPUs')\n",
    "plt.ylabel('Execution Time (seconds)')\n",
    "plt.title('Feature Extraction Times by Number of CPUs (Lower is better)')\n",
    "plt.xticks(x_ticks, num_workers)\n",
    "\n",
    "# Displaying time on top of each bar\n",
    "for bar, time_value in zip(bars, execution_times):\n",
    "    plt.text(bar.get_x() + bar.get_width() / 2, bar.get_height(), f'{time_value:.2f}', \n",
    "             ha='center', va='bottom')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e7fcdc5-c214-4be6-8fe2-56bd6a09f5c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "res = []\n",
    "for file_path in files[:10]:\n",
    "    f = delayed(extract_features)(file_path)\n",
    "    res.append(f)\n",
    "\n",
    "extracted_features = delayed(pd.concat)(res)\n",
    "extracted_features.visualize()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7507ad79-a4e5-438f-988d-329e67b6d7ec",
   "metadata": {},
   "source": [
    "<h3>Dask Task Graph</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b103b3ff-f783-460d-bfb8-b30b55d07129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as csv file\n",
    "data = df[0]\n",
    "data.to_csv(outfile_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766e8cf2-153a-4a84-9c61-cb2262457025",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Exploratory Data Analysis and Data Preprocessing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e926139-0230-40e4-8b9c-098f4c68142a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff973da-e801-4084-9769-d7267356d05b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(outfile_path)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263ddbed-cc02-4f02-973b-034c62a4dfe8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a520b91-0303-4534-9be9-e5669f852a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb011ff6-6816-40f6-b42f-0fbe130df8d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a2f595-c706-42d7-a2ac-d5557470e509",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373cecd4-b2b6-40bb-98fc-00d3f23a22f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display count of data rows for each genre\n",
    "genre_counts = data['label'].value_counts()\n",
    "print(genre_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c213be-8d54-4fb3-83c0-007d5e65b96d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#checking for missing value\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55088d2b-3fe6-4ce1-b889-facf83002343",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Computing the correlation matrix between the features of the dataset\n",
    "correlation_matrix = data.iloc[:, 1:-1].corr()\n",
    "\n",
    "#Plot\n",
    "plt.figure(figsize=(16, 11))\n",
    "color_palette = sns.color_palette(\"viridis\", as_cmap=True)\n",
    "\n",
    "#Drawing the heatmap\n",
    "sns.heatmap(correlation_matrix, cmap=color_palette, mask=np.triu(correlation_matrix), vmax=0.3, center=0, square=True, linewidths=0.5, cbar_kws={\"shrink\":0.5})\n",
    "\n",
    "plt.title('Feature Correlation Heatmap', fontsize=25)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.savefig(\"Feature_Correlation_Heatmap.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05528231-f647-428f-b104-a4387ef3f64d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Splitting data into features(X) and target (y)\n",
    "target_column = 'label'\n",
    "features = data.drop(columns=[target_column, 'file_name'])\n",
    "target = data[target_column]\n",
    "\n",
    "# Standardizing features to have a mean of 0 and variance of 1\n",
    "scaler = StandardScaler()\n",
    "features_normalized_df = scaler.fit_transform(features.astype(float))\n",
    "\n",
    "#Updating variables for clarity\n",
    "X = features_normalized_df\n",
    "y = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc846fe-b6b6-4c74-ad7a-27eb325d7ecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Encoding target labels\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64943266-d00b-46e1-bafb-aeb38d0ca089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd83dbf-f9d7-42b0-94bb-02f32f942e7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#70-30 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "346c231a-1d0f-45de-aa9d-d692c3a1ca62",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05c6f69-e7be-40c3-a2ec-8d1e38a2fd28",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee0d4ee-acb5-49f6-865c-fe21ded184aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Training and Classifying</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba28b3aa-70e9-4a0f-a6ac-684aa19c3429",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from xgboost import plot_tree, plot_importance\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve, classification_report\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import xgboost.dask as bst\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0a2168-4d08-4274-9320-2b7e0376a39a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name = \"\", cr = False):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_hat = model.predict(X_test)\n",
    "    print('Accuracy', model_name, ':', round(accuracy_score(y_test, y_hat), 5), '\\n')\n",
    "    if cr:\n",
    "        target_names = sorted(set(label_encoder.inverse_transform(y_encoded)))\n",
    "        print(classification_report(y_test, y_hat, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98e89ca-4e5f-4421-9fbe-8ce290bfb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=19)\n",
    "evaluate_model(knn, \"KNN\")\n",
    "\n",
    "rforest = RandomForestClassifier(n_estimators=1000, max_depth=10, random_state=0)\n",
    "evaluate_model(rforest, \"Random Forest\")\n",
    "\n",
    "svm = SVC(decision_function_shape=\"ovo\")\n",
    "evaluate_model(svm, \"SVM\")\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=1000)\n",
    "evaluate_model(xgb, \"XGBoost Classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2fcd28-f75e-4d9e-99f8-baffbcb3e25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=1000)\n",
    "model.fit(X_train, y_train, eval_metric='merror')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafc7e6d-36e3-4152-963d-6b23436a0c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Predictions on the training set\n",
    "train_predictions = model.predict(X_train)\n",
    "print(\"Training set predictions:\", train_predictions)\n",
    "\n",
    "#Predictions on the testing set\n",
    "test_predictions = model.predict(X_test)\n",
    "print(\"Testing set predictions:\", test_predictions)\n",
    "\n",
    "target_names = sorted(set(label_encoder.inverse_transform(y_encoded)))\n",
    "\n",
    "#Training accuracy\n",
    "training_accuracy = accuracy_score(y_train, train_predictions)\n",
    "print(f'Training accuracy: {training_accuracy}')\n",
    "\n",
    "#Classification report for the training set\n",
    "print(\"Training Classification Report:\")\n",
    "train_classification_report = classification_report(y_train, train_predictions, target_names=target_names)\n",
    "print(train_classification_report)\n",
    "\n",
    "#Testing accuracy\n",
    "testing_accuracy = accuracy_score(y_test, test_predictions)\n",
    "print(f'Testing accuracy: {testing_accuracy}')\n",
    "\n",
    "#Classification report for the testing set\n",
    "print(\"Testing Classification Report:\")\n",
    "test_classification_report = classification_report(y_test, test_predictions, target_names=target_names)\n",
    "print(test_classification_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218e4fa1-9046-47ab-9a16-74e35e2737ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, test_predictions)\n",
    "\n",
    "# Setting up the plot figure\n",
    "plt.figure(figsize=(16, 9))\n",
    "\n",
    "# Plotting the heatmap\n",
    "plt_labels = sorted(set(y))\n",
    "sns.heatmap(conf_matrix, cmap=\"BuPu\", annot=True, xticklabels=plt_labels, yticklabels=plt_labels)\n",
    "\n",
    "# Show plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e988ce3-30d5-46b4-a219-b842b16595a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2>Testing parallelization for model training</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5345dc96-ba4d-4d07-b8ba-5de4cd5c8602",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from joblib import parallel_backend\n",
    "from dask.distributed import Client\n",
    "from dask import array as da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3187f2-bfec-419a-a082-35a0d138f62b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# serial execution time for baseline\n",
    "start = time()\n",
    "model = XGBClassifier(n_estimators=1000)\n",
    "evaluate_model(model)\n",
    "serial_execution_time = time()-start\n",
    "print(f'serial XGBoost on took {serial_execution_time} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "728ba1dc-6eb9-4444-81e9-b001a015ff83",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h3>Try Dask for parallelization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f57509-d9ea-435f-b01f-e44c6c49661c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dict to hold execution times with number of cpu as key\n",
    "dask_parallel_times = {}\n",
    "# create dask array with appropriate chunk size\n",
    "da_X_train, da_y_train = da.from_array(X_train, chunks=(1000,108)), da.from_array(y_train, chunks=(1000,))\n",
    "da_X_test, da_y_test = da.from_array(X_test, chunks=(100,108)), da.from_array(y_test, chunks=(100))\n",
    "da_X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c9f26b-dcae-4799-aaad-76be7be13e4d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with Client(n_workers=2) as client:\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.client = client\n",
    "    model.fit(da_X_train, da_y_train)\n",
    "duration = time()-start\n",
    "dask_parallel_times[2] = duration\n",
    "print(f'Dask XGBoost on 2 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6c4efc-3e97-4aab-811a-4e197b4f95b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with Client(n_workers=4) as client:\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.client = client\n",
    "    model.fit(da_X_train, da_y_train)\n",
    "duration = time()-start\n",
    "dask_parallel_times[4] = duration\n",
    "print(f'Dask XGBoost on 4 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42de9e-270c-4f9f-9c3d-30ae72f91c0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with Client(n_workers=7) as client:\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.client = client\n",
    "    model.fit(da_X_train, da_y_train)\n",
    "duration = time()-start\n",
    "dask_parallel_times[7] = duration\n",
    "print(f'Dask XGBoost on 7 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f7bb83f-f159-46d6-9a81-932a20954e5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with Client(n_workers=14) as client:\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.client = client\n",
    "    model.fit(da_X_train, da_y_train)\n",
    "duration = time()-start\n",
    "dask_parallel_times[14] = duration\n",
    "print(f'Dask XGBoost on 14 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61af6f4e-918c-4f1a-a097-c8abcda4b7fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with Client(n_workers=21) as client:\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.client = client\n",
    "    model.fit(da_X_train, da_y_train)\n",
    "duration = time()-start\n",
    "dask_parallel_times[21] = duration\n",
    "print(f'Dask XGBoost on 21 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58c75ac-971d-47e0-9e93-ae4c6c6dbf24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with Client(n_workers=28) as client:\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.client = client\n",
    "    model.fit(da_X_train, da_y_train)\n",
    "duration = time()-start\n",
    "dask_parallel_times[28] = duration\n",
    "print(f'Dask XGBoost on 28 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd166458-fe26-4c1d-b230-db6477c749e0",
   "metadata": {},
   "source": [
    "<h3>Try Joblib for parallelization</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8621f726-fa11-45f4-9d69-f83bd29f357e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "joblib_parallel_times = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7501d2de-8687-4534-bea7-d4982e62c763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with parallel_backend('threading', n_jobs=2):\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "duration = time()-start\n",
    "joblib_parallel_times[2] = duration\n",
    "print(f'joblib XGBoost on 2 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571f0c62-d518-4488-915e-39675509ccc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with parallel_backend('threading', n_jobs=4):\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "duration = time()-start\n",
    "joblib_parallel_times[4] = duration\n",
    "print(f'joblib XGBoost on 4 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cde070-dc69-44d7-9868-7724aa4c5010",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with parallel_backend('threading', n_jobs=7):\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "duration = time()-start\n",
    "joblib_parallel_times[7] = duration\n",
    "print(f'joblib XGBoost on 7 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1036a9d-d37b-477e-bca1-53eabf74e67d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with parallel_backend('threading', n_jobs=14):\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "duration = time()-start\n",
    "joblib_parallel_times[14] = duration\n",
    "print(f'joblib XGBoost on 14 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547e695-a4ac-42d4-88da-b879e0126687",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with parallel_backend('threading', n_jobs=21):\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "duration = time()-start\n",
    "joblib_parallel_times[21] = duration\n",
    "print(f'joblib XGBoost on 21 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f4a9ae-fd80-493e-b4e6-7b03d2460cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start = time()\n",
    "with parallel_backend('threading', n_jobs=28):\n",
    "    model = XGBClassifier(n_estimators=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "duration = time()-start\n",
    "joblib_parallel_times[28] = duration\n",
    "print(f'joblib XGBoost on 28 CPUs took {duration} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f2e5c7-fa26-4208-80ce-c18cce1c0cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#finding the min times among dask and joblib\n",
    "fastest_dask = min(dask_parallel_times, key=dask_parallel_times.get)\n",
    "fastest_joblib = min(joblib_parallel_times, key=joblib_parallel_times.get)\n",
    "fastest_parallel = min(dask_parallel_times.get(fastest_dask), dask_parallel_times.get(fastest_joblib))\n",
    "fastest_cpu = -1\n",
    "if fastest_parallel == dask_parallel_times.get(fastest_dask):\n",
    "    fastest_cpu = fastest_dask\n",
    "else:\n",
    "    fastest_cpu = fastest_joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e3e7d7-eca6-4b6e-a204-f4a69dfdb99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the speedup achieved by using parallel on xgboost\n",
    "speedup = {}\n",
    "speedup_xgboost = serial_execution_time / fastest_parallel\n",
    "\n",
    "print(\"Speedup achieved for xgboost training: \", round(speedup_xgboost,2),\"X\")\n",
    "\n",
    "# #Calculating the efficiency achieved by using parallel on feature extraction\n",
    "efficiency_xgboost = speedup_xgboost / fastest_cpu\n",
    "\n",
    "print(\"Efficiency achieved for xgboost training: \", round(efficiency_xgboost,2), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "934d2bb0-7aaa-40e7-aa8a-a4c549f5eea4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "execution_times = []\n",
    "cpus = []\n",
    "for key in joblib_parallel_times:\n",
    "    cpus.append(key)\n",
    "    execution_times.append(joblib_parallel_times.get(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f274b-02d9-4799-ac4e-06d09b3725ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(dask_parallel_times)\n",
    "print(joblib_parallel_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbfc38b-6948-45bd-a99f-a6702f426a07",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_cpus = joblib_parallel_times.keys()\n",
    "parallel_techniques = {\n",
    "    'Joblib': joblib_parallel_times.values(),\n",
    "    'Dask': dask_parallel_times.values(),\n",
    "}\n",
    "\n",
    "x = np.arange(len(num_cpus))  # the label locations\n",
    "width = 0.25  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained')\n",
    "\n",
    "for attribute, exec_time in parallel_techniques.items():\n",
    "    offset = width * multiplier\n",
    "    rects = ax.bar(x + offset, exec_time, width, label=attribute)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_xlabel('Number of CPUs')\n",
    "ax.set_ylabel('Execution Time (seconds)')\n",
    "ax.set_title('Execution Time Comparison: Joblib vs Dask')\n",
    "ax.set_xticks(x + width, num_cpus)\n",
    "ax.legend(loc='upper left', ncols=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb668ff6-75f3-4e79-bbac-0502004eb7ef",
   "metadata": {},
   "source": [
    "<h2>Tuning XGBoost Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9175e93c-83cc-48c6-b96b-7850f1504842",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from dask_ml.model_selection import GridSearchCV\n",
    "from joblib import parallel_backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90fce36-2588-4766-946f-fb1c3dec6a9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train)\n",
    "y_train = pd.Series(y_train)\n",
    "\n",
    "dd_X_train = dd.from_pandas(X_train, npartitions=4)\n",
    "dd_y_train = dd.from_pandas(y_train, npartitions=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44735fff-f220-481a-b558-88607d2ac61a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(n_estimators=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26dc55-dd87-4d15-8a79-844078bc6395",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cad4921-3f76-4dec-ad35-4af4737722d2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(xgb, param_grid, cv=3)\n",
    "with Client(n_workers=16) as client:\n",
    "    grid_search.fit(dd_X_train, dd_y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92caef0d-86ec-4666-ae2d-dbf1053a6209",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = XGBClassifier(n_estimators=1000, learning_rate=0.05)\n",
    "evaluate_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
